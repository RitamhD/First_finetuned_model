{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 48.0,
  "eval_steps": 500,
  "global_step": 1248,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.7792207792207793,
      "grad_norm": 0.3939804136753082,
      "learning_rate": 0.0009892307692307694,
      "loss": 4.0034,
      "step": 20
    },
    {
      "epoch": 1.5454545454545454,
      "grad_norm": 0.3943502604961395,
      "learning_rate": 0.0009738461538461538,
      "loss": 0.2703,
      "step": 40
    },
    {
      "epoch": 2.311688311688312,
      "grad_norm": 0.2593156695365906,
      "learning_rate": 0.0009584615384615385,
      "loss": 0.1952,
      "step": 60
    },
    {
      "epoch": 3.0779220779220777,
      "grad_norm": 0.24207080900669098,
      "learning_rate": 0.0009430769230769231,
      "loss": 0.1692,
      "step": 80
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 0.3066955804824829,
      "learning_rate": 0.0009276923076923078,
      "loss": 0.1352,
      "step": 100
    },
    {
      "epoch": 4.623376623376624,
      "grad_norm": 0.2837882936000824,
      "learning_rate": 0.0009123076923076923,
      "loss": 0.1112,
      "step": 120
    },
    {
      "epoch": 5.3896103896103895,
      "grad_norm": 0.32581377029418945,
      "learning_rate": 0.000896923076923077,
      "loss": 0.1015,
      "step": 140
    },
    {
      "epoch": 6.1558441558441555,
      "grad_norm": 0.33955299854278564,
      "learning_rate": 0.0008815384615384615,
      "loss": 0.0847,
      "step": 160
    },
    {
      "epoch": 6.935064935064935,
      "grad_norm": 0.36429426074028015,
      "learning_rate": 0.0008661538461538461,
      "loss": 0.0767,
      "step": 180
    },
    {
      "epoch": 7.701298701298701,
      "grad_norm": 0.2730908989906311,
      "learning_rate": 0.0008507692307692308,
      "loss": 0.0666,
      "step": 200
    },
    {
      "epoch": 8.467532467532468,
      "grad_norm": 0.23982076346874237,
      "learning_rate": 0.0008353846153846154,
      "loss": 0.0625,
      "step": 220
    },
    {
      "epoch": 9.233766233766234,
      "grad_norm": 0.2331361323595047,
      "learning_rate": 0.00082,
      "loss": 0.0573,
      "step": 240
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.34925416111946106,
      "learning_rate": 0.0008046153846153846,
      "loss": 0.0529,
      "step": 260
    },
    {
      "epoch": 10.779220779220779,
      "grad_norm": 0.2777930498123169,
      "learning_rate": 0.0007892307692307692,
      "loss": 0.0466,
      "step": 280
    },
    {
      "epoch": 11.545454545454545,
      "grad_norm": 0.19840317964553833,
      "learning_rate": 0.0007738461538461538,
      "loss": 0.0439,
      "step": 300
    },
    {
      "epoch": 12.311688311688311,
      "grad_norm": 0.21009023487567902,
      "learning_rate": 0.0007584615384615385,
      "loss": 0.0438,
      "step": 320
    },
    {
      "epoch": 13.077922077922079,
      "grad_norm": 0.18886737525463104,
      "learning_rate": 0.0007430769230769231,
      "loss": 0.0423,
      "step": 340
    },
    {
      "epoch": 13.857142857142858,
      "grad_norm": 0.18100322782993317,
      "learning_rate": 0.0007276923076923077,
      "loss": 0.0387,
      "step": 360
    },
    {
      "epoch": 14.623376623376624,
      "grad_norm": 0.12850505113601685,
      "learning_rate": 0.0007123076923076923,
      "loss": 0.0363,
      "step": 380
    },
    {
      "epoch": 15.38961038961039,
      "grad_norm": 0.15507404506206512,
      "learning_rate": 0.000696923076923077,
      "loss": 0.0354,
      "step": 400
    },
    {
      "epoch": 16.155844155844157,
      "grad_norm": 0.11239974945783615,
      "learning_rate": 0.0006815384615384615,
      "loss": 0.0354,
      "step": 420
    },
    {
      "epoch": 16.935064935064936,
      "grad_norm": 0.12888658046722412,
      "learning_rate": 0.0006661538461538463,
      "loss": 0.0359,
      "step": 440
    },
    {
      "epoch": 17.7012987012987,
      "grad_norm": 0.16811323165893555,
      "learning_rate": 0.0006507692307692308,
      "loss": 0.036,
      "step": 460
    },
    {
      "epoch": 18.467532467532468,
      "grad_norm": 0.20923274755477905,
      "learning_rate": 0.0006353846153846155,
      "loss": 0.0358,
      "step": 480
    },
    {
      "epoch": 19.233766233766232,
      "grad_norm": 0.18154583871364594,
      "learning_rate": 0.00062,
      "loss": 0.0355,
      "step": 500
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.22997266054153442,
      "learning_rate": 0.0006046153846153846,
      "loss": 0.0348,
      "step": 520
    },
    {
      "epoch": 20.77922077922078,
      "grad_norm": 0.19768927991390228,
      "learning_rate": 0.0005892307692307692,
      "loss": 0.0337,
      "step": 540
    },
    {
      "epoch": 21.545454545454547,
      "grad_norm": 0.12979650497436523,
      "learning_rate": 0.000573846153846154,
      "loss": 0.0331,
      "step": 560
    },
    {
      "epoch": 22.31168831168831,
      "grad_norm": 0.10886847972869873,
      "learning_rate": 0.0005584615384615385,
      "loss": 0.032,
      "step": 580
    },
    {
      "epoch": 23.07792207792208,
      "grad_norm": 0.1409294307231903,
      "learning_rate": 0.0005430769230769231,
      "loss": 0.0328,
      "step": 600
    },
    {
      "epoch": 23.857142857142858,
      "grad_norm": 0.09732439368963242,
      "learning_rate": 0.0005276923076923077,
      "loss": 0.0316,
      "step": 620
    },
    {
      "epoch": 24.623376623376622,
      "grad_norm": 0.11568767577409744,
      "learning_rate": 0.0005123076923076923,
      "loss": 0.0308,
      "step": 640
    },
    {
      "epoch": 25.38961038961039,
      "grad_norm": 0.10090624541044235,
      "learning_rate": 0.0004969230769230769,
      "loss": 0.0312,
      "step": 660
    },
    {
      "epoch": 26.155844155844157,
      "grad_norm": 0.10943915694952011,
      "learning_rate": 0.0004815384615384615,
      "loss": 0.0307,
      "step": 680
    },
    {
      "epoch": 26.935064935064936,
      "grad_norm": 0.1501760184764862,
      "learning_rate": 0.0004661538461538462,
      "loss": 0.0305,
      "step": 700
    },
    {
      "epoch": 27.7012987012987,
      "grad_norm": 0.10582096129655838,
      "learning_rate": 0.00045076923076923077,
      "loss": 0.0301,
      "step": 720
    },
    {
      "epoch": 28.467532467532468,
      "grad_norm": 1.1080999374389648,
      "learning_rate": 0.00043538461538461537,
      "loss": 0.0302,
      "step": 740
    },
    {
      "epoch": 29.233766233766232,
      "grad_norm": 0.09464728832244873,
      "learning_rate": 0.00042,
      "loss": 0.0305,
      "step": 760
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.11779014766216278,
      "learning_rate": 0.0004046153846153846,
      "loss": 0.0306,
      "step": 780
    },
    {
      "epoch": 30.77922077922078,
      "grad_norm": 0.09734641760587692,
      "learning_rate": 0.0003892307692307692,
      "loss": 0.0298,
      "step": 800
    },
    {
      "epoch": 31.545454545454547,
      "grad_norm": 0.10931111872196198,
      "learning_rate": 0.00037384615384615386,
      "loss": 0.0294,
      "step": 820
    },
    {
      "epoch": 32.311688311688314,
      "grad_norm": 0.10750142484903336,
      "learning_rate": 0.00035846153846153846,
      "loss": 0.03,
      "step": 840
    },
    {
      "epoch": 33.077922077922075,
      "grad_norm": 0.12851810455322266,
      "learning_rate": 0.00034307692307692305,
      "loss": 0.0296,
      "step": 860
    },
    {
      "epoch": 33.857142857142854,
      "grad_norm": 0.09902887791395187,
      "learning_rate": 0.0003276923076923077,
      "loss": 0.0291,
      "step": 880
    },
    {
      "epoch": 34.62337662337662,
      "grad_norm": 0.10499411076307297,
      "learning_rate": 0.0003123076923076923,
      "loss": 0.0289,
      "step": 900
    },
    {
      "epoch": 35.38961038961039,
      "grad_norm": 0.28930333256721497,
      "learning_rate": 0.0002969230769230769,
      "loss": 0.0285,
      "step": 920
    },
    {
      "epoch": 36.15584415584416,
      "grad_norm": 0.37376195192337036,
      "learning_rate": 0.00028153846153846154,
      "loss": 0.0296,
      "step": 940
    },
    {
      "epoch": 36.935064935064936,
      "grad_norm": 0.14445777237415314,
      "learning_rate": 0.00026615384615384614,
      "loss": 0.029,
      "step": 960
    },
    {
      "epoch": 37.701298701298704,
      "grad_norm": 0.2026805281639099,
      "learning_rate": 0.00025076923076923073,
      "loss": 0.0282,
      "step": 980
    },
    {
      "epoch": 38.467532467532465,
      "grad_norm": 0.24072864651679993,
      "learning_rate": 0.00023538461538461538,
      "loss": 0.0284,
      "step": 1000
    },
    {
      "epoch": 39.23376623376623,
      "grad_norm": 0.42850738763809204,
      "learning_rate": 0.00022,
      "loss": 0.0283,
      "step": 1020
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.16548806428909302,
      "learning_rate": 0.00020461538461538463,
      "loss": 0.0278,
      "step": 1040
    },
    {
      "epoch": 40.77922077922078,
      "grad_norm": 0.20358435809612274,
      "learning_rate": 0.00018923076923076923,
      "loss": 0.027,
      "step": 1060
    },
    {
      "epoch": 41.54545454545455,
      "grad_norm": 0.2554565370082855,
      "learning_rate": 0.00017384615384615385,
      "loss": 0.0273,
      "step": 1080
    },
    {
      "epoch": 42.311688311688314,
      "grad_norm": 0.16624850034713745,
      "learning_rate": 0.00015846153846153847,
      "loss": 0.0268,
      "step": 1100
    },
    {
      "epoch": 43.077922077922075,
      "grad_norm": 0.2716183364391327,
      "learning_rate": 0.00014307692307692307,
      "loss": 0.0271,
      "step": 1120
    },
    {
      "epoch": 43.857142857142854,
      "grad_norm": 0.10517952591180801,
      "learning_rate": 0.0001276923076923077,
      "loss": 0.0263,
      "step": 1140
    },
    {
      "epoch": 44.62337662337662,
      "grad_norm": 0.09187944233417511,
      "learning_rate": 0.0001123076923076923,
      "loss": 0.0258,
      "step": 1160
    },
    {
      "epoch": 45.38961038961039,
      "grad_norm": 0.12575533986091614,
      "learning_rate": 9.692307692307692e-05,
      "loss": 0.0261,
      "step": 1180
    },
    {
      "epoch": 46.15584415584416,
      "grad_norm": 0.28765031695365906,
      "learning_rate": 8.153846153846153e-05,
      "loss": 0.0259,
      "step": 1200
    },
    {
      "epoch": 46.935064935064936,
      "grad_norm": 0.1975240409374237,
      "learning_rate": 6.615384615384616e-05,
      "loss": 0.0257,
      "step": 1220
    },
    {
      "epoch": 47.701298701298704,
      "grad_norm": 0.10682596266269684,
      "learning_rate": 5.0769230769230766e-05,
      "loss": 0.0254,
      "step": 1240
    }
  ],
  "logging_steps": 20,
  "max_steps": 1300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.756178254135296e+16,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
